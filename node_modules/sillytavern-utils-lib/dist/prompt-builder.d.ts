import { ChatCompletionMessage, ChatMessage } from './types/index.js';
export interface Message extends ChatCompletionMessage {
    ignoreInstruct?: boolean;
    source?: ChatMessage;
}
export interface BuildPromptOptions {
    targetCharacterId?: number;
    presetName?: string;
    instructName?: string;
    contextName?: string;
    syspromptName?: string;
    maxContext?: number | 'preset' | 'active';
    includeNames?: boolean;
    ignoreCharacterFields?: boolean;
    ignoreAuthorNote?: boolean;
    ignoreWorldInfo?: boolean;
    /**
     * Use both -1 to not include any messages
     */
    messageIndexesBetween?: {
        start?: number;
        end?: number;
    };
}
/**
 * Builds chat prompt. Don't expect a perfect chat prompt like ST. But I would give guarantee that it will cover 98% of the cases.
 *
 * Token calculation is crippled. We only calculating tokens for the chat history. For example, If your max context is 16k, total token will be 16k + world info, author note, extensionPrompts, etc. Better than nothing.
 * @param targetMessageIndex - Last message index to include in prompt
 * @param [param1={}] - Options
 */
export declare function buildPrompt(api: string, { targetCharacterId, presetName, instructName, contextName, syspromptName, maxContext, includeNames, ignoreCharacterFields, ignoreAuthorNote, ignoreWorldInfo, messageIndexesBetween, }?: BuildPromptOptions): Promise<{
    result: Message[];
    warnings?: string[];
}>;
//# sourceMappingURL=prompt-builder.d.ts.map